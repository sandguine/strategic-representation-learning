{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ea4019",
   "metadata": {},
   "source": [
    "# Strategic Representation Learning: Mathematical Framework\n",
    "\n",
    "This notebook demonstrates the core mathematical concepts of strategic equivalence classes in multi-agent interactions.\n",
    "\n",
    "## Mathematical Framework\n",
    "\n",
    "### Soft Best Response\n",
    "$$BR^\\tau_i(a_i \\mid \\pi_{-i}) = \\frac{\\exp(Q_{\\pi_{-i}}(a_i)/\\tau)}{\\sum_{a'} \\exp(Q_{\\pi_{-i}}(a')/\\tau)}$$\n",
    "\n",
    "### Strategic Influence\n",
    "$$I(\\pi_i, \\pi_j) = D_{KL}(BR^\\tau(\\pi_i) \\parallel BR^\\tau(\\pi_j))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3392e27",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def softmax(q_values, tau=1.0):\n",
    "    \"\"\"Compute softmax with temperature parameter tau.\"\"\"\n",
    "    q = np.array(q_values)\n",
    "    q = q - np.max(q)  # numerical stability\n",
    "    return np.exp(q / tau) / np.sum(np.exp(q / tau))\n",
    "\n",
    "# Define game settings\n",
    "games = {\n",
    "    \"competitive\": {\n",
    "        \"always_head\": [1, -1],\n",
    "        \"always_tail\": [-1, 1],\n",
    "        \"random\": [0, 0],\n",
    "    },\n",
    "    \"mixed_motive\": {\n",
    "        \"greedy_red\": [0.5, 0.3],\n",
    "        \"hovering\": [0.4, 0.4],\n",
    "        \"blocking\": [0.6, 0.2],\n",
    "    },\n",
    "    \"cooperative\": {\n",
    "        \"clockwise\": [0.8, 0.2],\n",
    "        \"pause_then_deliver\": [0.82, 0.18],\n",
    "        \"idle_helper\": [0.81, 0.19],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deffc90",
   "metadata": {},
   "source": [
    "### Best Response Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599eb520",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_br_distributions(tau):\n",
    "    \"\"\"Plot best response distributions for all settings.\"\"\"\n",
    "    fig = make_subplots(rows=1, cols=3, \n",
    "                       subplot_titles=[f\"{setting.title()} Setting\" for setting in games.keys()])\n",
    "    \n",
    "    for i, (setting, co_policies) in enumerate(games.items(), 1):\n",
    "        for policy_name, q_values in co_policies.items():\n",
    "            br = softmax(q_values, tau)\n",
    "            fig.add_trace(\n",
    "                go.Bar(name=policy_name, x=[\"Action 1\", \"Action 2\"], y=br),\n",
    "                row=1, col=i\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=400, \n",
    "        width=1200, \n",
    "        title=f\"Best Response Distributions (τ={tau:.2f})\",\n",
    "        barmode='group',\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Interactive temperature control\n",
    "tau_slider = widgets.FloatSlider(value=0.1, min=0.01, max=2.0, step=0.01, description='Temperature (τ):')\n",
    "widgets.interactive(plot_br_distributions, tau=tau_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fe0ce",
   "metadata": {},
   "source": [
    "### Strategic Influence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8848f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_strategic_influence(base_policy, target_policy, setting, tau=0.1):\n",
    "    \"\"\"Compute strategic influence between policies.\"\"\"\n",
    "    base_br = softmax(games[setting][base_policy], tau)\n",
    "    target_br = softmax(games[setting][target_policy], tau)\n",
    "    return entropy(base_br, target_br)\n",
    "\n",
    "def plot_strategic_influence(setting, tau=0.1):\n",
    "    \"\"\"Plot strategic influence matrix.\"\"\"\n",
    "    co_policies = list(games[setting].keys())\n",
    "    influence_matrix = np.zeros((len(co_policies), len(co_policies)))\n",
    "    \n",
    "    for i, policy_i in enumerate(co_policies):\n",
    "        for j, policy_j in enumerate(co_policies):\n",
    "            influence_matrix[i, j] = compute_strategic_influence(policy_i, policy_j, setting, tau)\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=influence_matrix,\n",
    "        x=co_policies,\n",
    "        y=co_policies,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Strategic Influence')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{setting.title()} Setting: Strategic Influence Matrix (τ={tau:.2f})\",\n",
    "        xaxis_title=\"Target Policy\",\n",
    "        yaxis_title=\"Base Policy\",\n",
    "        height=500,\n",
    "        width=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Interactive controls\n",
    "setting_dropdown = widgets.Dropdown(options=list(games.keys()), description='Setting:')\n",
    "tau_slider = widgets.FloatSlider(value=0.1, min=0.01, max=2.0, step=0.01, description='Temperature (τ):')\n",
    "widgets.interactive(plot_strategic_influence, setting=setting_dropdown, tau=tau_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bffb2c",
   "metadata": {},
   "source": [
    "### SEC Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sec_evolution(setting, n_steps=10, tau=0.1):\n",
    "    \"\"\"Simulate SEC evolution over time.\"\"\"\n",
    "    co_policies = list(games[setting].keys())\n",
    "    trajectory = []\n",
    "    current_policy = np.random.choice(co_policies)\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        current_br = softmax(games[setting][current_policy], tau)\n",
    "        sec = []\n",
    "        sec_distances = []\n",
    "        \n",
    "        for policy in co_policies:\n",
    "            br = softmax(games[setting][policy], tau)\n",
    "            kl_div = entropy(current_br, br)\n",
    "            sec_distances.append(kl_div)\n",
    "            if kl_div <= 0.05:\n",
    "                sec.append(policy)\n",
    "        \n",
    "        trajectory.append({\n",
    "            'timestep': t,\n",
    "            'current_policy': current_policy,\n",
    "            'sec_size': len(sec),\n",
    "            'avg_distance': np.mean(sec_distances),\n",
    "            'sec_members': ','.join(sec)\n",
    "        })\n",
    "        \n",
    "        next_policy = np.random.choice(co_policies)\n",
    "        trajectory[-1]['next_policy'] = next_policy\n",
    "        current_policy = next_policy\n",
    "    \n",
    "    return pd.DataFrame(trajectory)\n",
    "\n",
    "def plot_sec_evolution(setting, n_steps=10, tau=0.1):\n",
    "    \"\"\"Plot SEC evolution over time.\"\"\"\n",
    "    df = simulate_sec_evolution(setting, n_steps, tau)\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                       subplot_titles=[\"SEC Size Over Time\", \"Average KL Divergence\"])\n",
    "    \n",
    "    # Plot SEC size\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['timestep'],\n",
    "            y=df['sec_size'],\n",
    "            mode='lines+markers',\n",
    "            name='SEC Size',\n",
    "            hovertemplate=\"Timestep: %{x}<br>\" +\n",
    "                         \"SEC Size: %{y}<br>\" +\n",
    "                         \"Current Policy: %{customdata[0]}<br>\" +\n",
    "                         \"Next Policy: %{customdata[1]}<extra></extra>\",\n",
    "            customdata=[[row['current_policy'], row['next_policy']] for _, row in df.iterrows()]\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot average KL divergence\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['timestep'],\n",
    "            y=df['avg_distance'],\n",
    "            mode='lines+markers',\n",
    "            name='Avg KL Divergence',\n",
    "            hovertemplate=\"Timestep: %{x}<br>\" +\n",
    "                         \"Avg KL Div: %{y:.3f}<br>\" +\n",
    "                         \"SEC Members: %{customdata}<extra></extra>\",\n",
    "            customdata=df['sec_members']\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1000,\n",
    "        title=f\"{setting.title()} Setting: SEC Evolution (τ={tau:.2f})\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Timestep\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Timestep\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Policies\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"KL Divergence\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Interactive controls\n",
    "setting_dropdown = widgets.Dropdown(options=list(games.keys()), description='Setting:')\n",
    "tau_slider = widgets.FloatSlider(value=0.1, min=0.01, max=2.0, step=0.01, description='Temperature (τ):')\n",
    "n_steps_slider = widgets.IntSlider(value=10, min=5, max=50, step=1, description='Steps:')\n",
    "widgets.interactive(plot_sec_evolution, \n",
    "                   setting=setting_dropdown,\n",
    "                   tau=tau_slider,\n",
    "                   n_steps=n_steps_slider) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
